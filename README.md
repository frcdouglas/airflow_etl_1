# airflow_etl_1

## ğŸ“Œ DescriÃ§Ã£o | Description

### ğŸ‡§ğŸ‡· PortuguÃªs
Este projeto demonstra a utilizaÃ§Ã£o do **Apache Airflow** para orquestrar uma **pipeline de dados ETL (Extract, Transform, Load)**.  
A pipeline realiza a extraÃ§Ã£o de dados a partir de um arquivo **CSV**, transforma os dados de forma simples e carrega as informaÃ§Ãµes em um banco de dados **SQLite**.

O objetivo principal do projeto Ã© **demonstrar conceitos fundamentais do Airflow**, como:
- CriaÃ§Ã£o de DAGs
- DependÃªncia entre tarefas
- Uso de **XCom** para comunicaÃ§Ã£o entre tasks
- OrquestraÃ§Ã£o de pipelines utilizando **Docker**

> âš ï¸ O uso do SQLite Ã© **apenas didÃ¡tico**. A mesma pipeline pode ser facilmente adaptada para outros bancos de dados (PostgreSQL, MySQL, etc).

---

### ğŸ‡ºğŸ‡¸ English
This project demonstrates the use of **Apache Airflow** to orchestrate an **ETL (Extract, Transform, Load) data pipeline**.  
The pipeline extracts data from a **CSV file**, applies simple transformations, and loads the data into a **SQLite database**.

The main goal of this project is to demonstrate **core Airflow concepts**, such as:
- DAG creation
- Task dependencies
- **XCom** usage for task communication
- Pipeline orchestration using **Docker**

> âš ï¸ SQLite is used **for educational purposes only**. This pipeline can be easily adapted to other databases such as PostgreSQL or MySQL.

---

## ğŸ¥ DemonstraÃ§Ã£o | Demo

[![DemonstraÃ§Ã£o do projeto](https://img.youtube.com/vi/nUfdyS666hc/0.jpg)](https://www.youtube.com/watch?v=nUfdyS666hc)

â–¶ Clique na imagem para assistir Ã  execuÃ§Ã£o completa do pipeline no Airflow.  
â–¶ Click the image to watch the full pipeline execution.

---

## ğŸ—ï¸ Arquitetura da Pipeline | Pipeline Architecture

### ETL Flow
Start
  â†“
Setup Database
  â†“
Extract (CSV)
  â†“
Transform (Python)
  â†“
Load (SQLite)
  â†“
End

## Estrutura da DAG | DAG Structure
A DAG users_etl_pipeline Ã© composta pelas seguintes tasks:

# start
Task inicial (EmptyOperator)
# setup_database
Cria a tabela users no banco SQLite (caso nÃ£o exista) e limpa os dados antes da carga
# extract
LÃª os dados do arquivo users.csv
# transform
Aplica transformaÃ§Ãµes simples (neste projeto, apenas repassa os dados)
# load
Insere os registros no banco de dados SQLite
# end
Task final (EmptyOperator)

## ğŸ§° Tecnologias Utilizadas | Technologies Used

- Apache Airflow
- Python
- Docker & Docker Compose
- SQLite
- Pandas

## ğŸ¯ Objetivo do Projeto | Project Goal

- Demonstrar o uso do Apache Airflow para orquestraÃ§Ã£o de pipelines
- Aplicar conceitos de ETL na prÃ¡tica
- Criar um projeto simples, didÃ¡tico e replicÃ¡vel
- Servir como projeto de portfÃ³lio para estudos em engenharia de dados
